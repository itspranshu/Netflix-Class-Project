{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_models.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# ===========================\n",
    "# 1. Data Loading & Cleaning\n",
    "# ===========================\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\psngh\\OneDrive\\Desktop\\netflix_customer_churn1.csv\"\n",
    "MODELS_DIR = r\"C:\\Users\\psngh\\OneDrive\\Desktop\\models\"\n",
    "\n",
    "# Create models directory if not exists\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# ===========================\n",
    "# 2. Encoding\n",
    "# ===========================\n",
    "\n",
    "# Label encode target variable churned\n",
    "le_churn = LabelEncoder()\n",
    "df['churned'] = le_churn.fit_transform(df['churned'])\n",
    "\n",
    "# One-hot encode specified categorical columns with drop_first=True\n",
    "one_hot_cols = ['gender', 'subscription_type', 'region', 'device', 'payment_method', 'favorite_genre']\n",
    "df = pd.get_dummies(df, columns=one_hot_cols, drop_first=True)\n",
    "\n",
    "# ===========================\n",
    "# 3. Feature Engineering\n",
    "# ===========================\n",
    "\n",
    "df['total_charges'] = df['watch_hours'] * df['monthly_fee']\n",
    "\n",
    "# ===========================\n",
    "# 4. Derived Target Creation\n",
    "# ===========================\n",
    "\n",
    "# Customer Engagement Level using quantile binning on avg_watch_time_per_day\n",
    "df['engagement_level'] = pd.qcut(df['avg_watch_time_per_day'], q=3, labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# Customer Lifetime Value (CLV) Tier using quantile binning on total_charges\n",
    "df['clv_tier'] = pd.qcut(df['total_charges'], q=3, labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "# ===========================\n",
    "# 5. K-Means Clustering\n",
    "# ===========================\n",
    "\n",
    "cluster_features = ['age', 'monthly_fee', 'total_charges']\n",
    "X_cluster = df[cluster_features]\n",
    "\n",
    "scaler_kmeans = StandardScaler()\n",
    "X_cluster_scaled = scaler_kmeans.fit_transform(X_cluster)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(X_cluster_scaled)\n",
    "\n",
    "# ===========================\n",
    "# 6. Churn Prediction Model\n",
    "# ===========================\n",
    "\n",
    "# Features and target for churn prediction\n",
    "drop_cols_churn = ['customer_id', 'churned', 'Cluster', 'engagement_level', 'clv_tier']\n",
    "X_churn = df.drop(columns=drop_cols_churn)\n",
    "y_churn = df['churned']\n",
    "\n",
    "X_train_churn, X_test_churn, y_train_churn, y_test_churn = train_test_split(\n",
    "    X_churn, y_churn, test_size=0.3, random_state=42, stratify=y_churn)\n",
    "\n",
    "scaler_churn = StandardScaler()\n",
    "X_train_churn_scaled = scaler_churn.fit_transform(X_train_churn)\n",
    "X_test_churn_scaled = scaler_churn.transform(X_test_churn)\n",
    "\n",
    "churn_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "churn_model.fit(X_train_churn_scaled, y_train_churn)\n",
    "\n",
    "y_pred_churn = churn_model.predict(X_test_churn_scaled)\n",
    "\n",
    "accuracy_churn = accuracy_score(y_test_churn, y_pred_churn)\n",
    "precision_churn = precision_score(y_test_churn, y_pred_churn)\n",
    "recall_churn = recall_score(y_test_churn, y_pred_churn)\n",
    "f1_churn = f1_score(y_test_churn, y_pred_churn)\n",
    "\n",
    "print(\"Churn Prediction Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_churn:.4f}\")\n",
    "print(f\"Precision: {precision_churn:.4f}\")\n",
    "print(f\"Recall: {recall_churn:.4f}\")\n",
    "print(f\"F1-score: {f1_churn:.4f}\")\n",
    "\n",
    "# ===========================\n",
    "# 7. Engagement Level Prediction Model\n",
    "# ===========================\n",
    "\n",
    "# Features and target for engagement level prediction\n",
    "drop_cols_engagement = ['customer_id', 'churned', 'Cluster', 'engagement_level', 'clv_tier']\n",
    "X_engagement = df.drop(columns=drop_cols_engagement)\n",
    "y_engagement = df['engagement_level']\n",
    "\n",
    "X_train_eng, X_test_eng, y_train_eng, y_test_eng = train_test_split(\n",
    "    X_engagement, y_engagement, test_size=0.3, random_state=42, stratify=y_engagement)\n",
    "\n",
    "scaler_engagement = StandardScaler()\n",
    "X_train_eng_scaled = scaler_engagement.fit_transform(X_train_eng)\n",
    "X_test_eng_scaled = scaler_engagement.transform(X_test_eng)\n",
    "\n",
    "engagement_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='ovr')\n",
    "engagement_model.fit(X_train_eng_scaled, y_train_eng)\n",
    "\n",
    "y_pred_eng = engagement_model.predict(X_test_eng_scaled)\n",
    "accuracy_engagement = accuracy_score(y_test_eng, y_pred_eng)\n",
    "\n",
    "print(\"\\nEngagement Level Prediction Model Accuracy:\")\n",
    "print(f\"Accuracy: {accuracy_engagement:.4f}\")\n",
    "\n",
    "# ===========================\n",
    "# 8. CLV Tier Prediction Model\n",
    "# ===========================\n",
    "\n",
    "# Features and target for CLV tier prediction\n",
    "drop_cols_clv = ['customer_id', 'churned', 'Cluster', 'engagement_level', 'clv_tier']\n",
    "X_clv = df.drop(columns=drop_cols_clv)\n",
    "y_clv = df['clv_tier']\n",
    "\n",
    "X_train_clv, X_test_clv, y_train_clv, y_test_clv = train_test_split(\n",
    "    X_clv, y_clv, test_size=0.3, random_state=42, stratify=y_clv)\n",
    "\n",
    "scaler_clv = StandardScaler()\n",
    "X_train_clv_scaled = scaler_clv.fit_transform(X_train_clv)\n",
    "X_test_clv_scaled = scaler_clv.transform(X_test_clv)\n",
    "\n",
    "clv_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='ovr')\n",
    "clv_model.fit(X_train_clv_scaled, y_train_clv)\n",
    "\n",
    "y_pred_clv = clv_model.predict(X_test_clv_scaled)\n",
    "accuracy_clv = accuracy_score(y_test_clv, y_pred_clv)\n",
    "\n",
    "print(\"\\nCLV Tier Prediction Model Accuracy:\")\n",
    "print(f\"Accuracy: {accuracy_clv:.4f}\")\n",
    "\n",
    "# ===========================\n",
    "# 9. Model & Object Saving\n",
    "# ===========================\n",
    "\n",
    "# Save models\n",
    "joblib.dump(churn_model, os.path.join(MODELS_DIR, 'churn_model.pkl'))\n",
    "joblib.dump(engagement_model, os.path.join(MODELS_DIR, 'engagement_model.pkl'))\n",
    "joblib.dump(clv_model, os.path.join(MODELS_DIR, 'clv_model.pkl'))\n",
    "joblib.dump(kmeans, os.path.join(MODELS_DIR, 'kmeans_model.pkl'))\n",
    "\n",
    "# Save scalers\n",
    "joblib.dump(scaler_churn, os.path.join(MODELS_DIR, 'scaler_churn.pkl'))\n",
    "joblib.dump(scaler_engagement, os.path.join(MODELS_DIR, 'scaler_engagement.pkl'))\n",
    "joblib.dump(scaler_clv, os.path.join(MODELS_DIR, 'scaler_clv.pkl'))\n",
    "joblib.dump(scaler_kmeans, os.path.join(MODELS_DIR, 'scaler_kmeans.pkl'))\n",
    "\n",
    "# Save feature columns used for models (all same features for simplicity)\n",
    "feature_columns = X_churn.columns.tolist()\n",
    "joblib.dump(feature_columns, os.path.join(MODELS_DIR, 'feature_columns.pkl'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
